{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Donkey Car Training using Google Colab-KR Edition",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pletalk/EMPV-RPI-AutoDriving/blob/master/03-Donkeycar-Training-Colab/Donkey_Car_Training_using_Google_Colab_KR_Edition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "BlmQIFSLZDdc"
      },
      "source": [
        "# Google Colaboratory를 활용한 동키카 학습을 위한 단계별 가이드\n",
        "\n",
        "@2020-08-01/Ignitespark\n",
        "\n",
        "Google에서 지원하는 Colaboratory 환경에서 Donkey의 주행 영상데이타를 활용해서 신경회로망의 학습을 단계적으로 수행하도록 안내하는 노트북입니다.\n",
        "\n",
        "원할한 수행을 위해서 메뉴의 런타임 > 런타임 유형변경에서 GPU/TPU를 선택해 주세요.\n",
        "\n",
        "*(Reference)* \n",
        "\n",
        "본 코드는 Sachindroid8님이 작성하신 Google Colaboratory기반의 Donkey Training 주피터 노트북에 기반하여 내용을 한글화하고, 교육에 필요한 내용을 추가하여 확장하였습니다. Sachindroid8님이 작성하신 Git의 코드 주소는 아래와 같습니다.\n",
        "\n",
        "https://github.com/sachindroid8/self-driving-car-using-google-colab\n",
        "\n",
        "<변경내용>\n",
        "* 08-01 \n",
        "    * Tensorflow설치(2.0alpha)코드 삭제 -> 현재 2.2버전지원\n",
        "    * 수행코드 일부변경"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PcxPuVeq6rQI",
        "colab_type": "text"
      },
      "source": [
        "# 0 > Google Colaboratory를 사용하기 전에 알아두어야할 사항들"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z17oTx4n6xn_",
        "colab_type": "text"
      },
      "source": [
        "Google Colaboratory는 구글이 지원하는 머신러닝 및 데이타처리를 위한 무료 서비스 플랫폼입니다. Google Colaboratory에서는 고성능의 GPU를 제공하여 머신러닝의 학습속도를 빠르게 수행할 수 있는 우수한 기능을 제공하고 있습니다. 이런 기능들을 활용하는데 있어서 반드시 알아두어야할 사항들은 아래와 같습니다.\n",
        "\n",
        "\n",
        "* Google Colaboratory는 12시간 동안만 사용 가능합니다. 사용자가 프로그램 수행을 위한 노트를 개설하고 수행하는데 있어서 최대 12시간 이내에서만 사용할 수 있습니다. Google Colaboratory는 12시간이 지나면 개인에게 할당했던 모든 컴퓨팅 자원(CPU,메모리,GPU등)을 리셋(재설정)합니다.\n",
        "\n",
        "* 12시간 이내라도 80분간 사용하지 않으면, 개인에게 할당했던 모든 컴퓨팅 자원(CPU,메모리,GPU등)을 리셋(재설정)합니다.\n",
        "\n",
        "* 할당된 자원이 리셋(재설정)되었다고 다시 사용하지 못하는 것은 아닙니다. 개인의 구글 드라이브에 저장된 Google Laboratory에서 작성한 주피터 노트북을 다시 로드하고 프로젝트를 새로이 시작하면 됩니다. 또 다른 12시간의 개발과 테스팅 시간이 시작됩니다.\n",
        "\n",
        "* Google Laboratory에서 수행한 내용들은 주피터 노트북에 과정과 내용을 기록하여 재 사용가능하도록 합니다. 생성하거나 사용한 노트북은 개인의 구글 드라이브에 파일로 저장이 가능합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5l4MpFXFip98",
        "colab_type": "text"
      },
      "source": [
        "# 1 > Google Colaboratory의 컴퓨팅 환경\n",
        "\n",
        "구글의 Colaboratory에서 지원되는 기본적인 컴퓨팅 환경의 다양한 정보들을 통해 성능을 확인해봅니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EJjLud26jNI7",
        "colab_type": "text"
      },
      "source": [
        "## 1.1 OS 확인하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "og0R-h2zipTQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "94eb68cd-d8ef-46f1-ac01-bc595ceb5662"
      },
      "source": [
        "! cat /etc/issue.net"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Ubuntu 18.04.3 LTS\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z4QMph5LjUeE",
        "colab_type": "text"
      },
      "source": [
        "## 1.2 Google Colaboratory GPU 정보보기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c8tmMHYcjZ4c",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "ea357815-8618-4209-db82-7026b4f45477"
      },
      "source": [
        "! nvidia-smi"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sat Aug  1 05:50:37 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 450.57       Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   72C    P8    32W / 149W |      0MiB / 11441MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TU6Q-ZqFjp1M",
        "colab_type": "text"
      },
      "source": [
        "## 1.3 메모리 용량 파악하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GC0zt4zNjqK3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 816
        },
        "outputId": "0b49d581-c4cb-4be3-a4e4-0c27cee80f72"
      },
      "source": [
        "! cat /proc/meminfo"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MemTotal:       13333556 kB\n",
            "MemFree:         9543040 kB\n",
            "MemAvailable:   12452092 kB\n",
            "Buffers:           79924 kB\n",
            "Cached:          2964764 kB\n",
            "SwapCached:            0 kB\n",
            "Active:           914576 kB\n",
            "Inactive:        2575148 kB\n",
            "Active(anon):     411724 kB\n",
            "Inactive(anon):      348 kB\n",
            "Active(file):     502852 kB\n",
            "Inactive(file):  2574800 kB\n",
            "Unevictable:           0 kB\n",
            "Mlocked:               0 kB\n",
            "SwapTotal:             0 kB\n",
            "SwapFree:              0 kB\n",
            "Dirty:               952 kB\n",
            "Writeback:             0 kB\n",
            "AnonPages:        444960 kB\n",
            "Mapped:           224788 kB\n",
            "Shmem:               964 kB\n",
            "Slab:             185580 kB\n",
            "SReclaimable:     144504 kB\n",
            "SUnreclaim:        41076 kB\n",
            "KernelStack:        3668 kB\n",
            "PageTables:         5548 kB\n",
            "NFS_Unstable:          0 kB\n",
            "Bounce:                0 kB\n",
            "WritebackTmp:          0 kB\n",
            "CommitLimit:     6666776 kB\n",
            "Committed_AS:    2565832 kB\n",
            "VmallocTotal:   34359738367 kB\n",
            "VmallocUsed:           0 kB\n",
            "VmallocChunk:          0 kB\n",
            "Percpu:              920 kB\n",
            "AnonHugePages:         0 kB\n",
            "ShmemHugePages:        0 kB\n",
            "ShmemPmdMapped:        0 kB\n",
            "HugePages_Total:       0\n",
            "HugePages_Free:        0\n",
            "HugePages_Rsvd:        0\n",
            "HugePages_Surp:        0\n",
            "Hugepagesize:       2048 kB\n",
            "Hugetlb:               0 kB\n",
            "DirectMap4k:      156860 kB\n",
            "DirectMap2M:     6133760 kB\n",
            "DirectMap1G:     9437184 kB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YhlZkOuQj1kW",
        "colab_type": "text"
      },
      "source": [
        "## 1.4 CPU 정보 파악하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1e4y0p2fj1sq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 955
        },
        "outputId": "c44419ed-718b-4c01-9153-6cb29d26ba79"
      },
      "source": [
        "! cat /proc/cpuinfo"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "processor\t: 0\n",
            "vendor_id\t: GenuineIntel\n",
            "cpu family\t: 6\n",
            "model\t\t: 63\n",
            "model name\t: Intel(R) Xeon(R) CPU @ 2.30GHz\n",
            "stepping\t: 0\n",
            "microcode\t: 0x1\n",
            "cpu MHz\t\t: 2299.998\n",
            "cache size\t: 46080 KB\n",
            "physical id\t: 0\n",
            "siblings\t: 2\n",
            "core id\t\t: 0\n",
            "cpu cores\t: 1\n",
            "apicid\t\t: 0\n",
            "initial apicid\t: 0\n",
            "fpu\t\t: yes\n",
            "fpu_exception\t: yes\n",
            "cpuid level\t: 13\n",
            "wp\t\t: yes\n",
            "flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm invpcid_single ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 avx2 smep bmi2 erms invpcid xsaveopt arat md_clear arch_capabilities\n",
            "bugs\t\t: cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs\n",
            "bogomips\t: 4599.99\n",
            "clflush size\t: 64\n",
            "cache_alignment\t: 64\n",
            "address sizes\t: 46 bits physical, 48 bits virtual\n",
            "power management:\n",
            "\n",
            "processor\t: 1\n",
            "vendor_id\t: GenuineIntel\n",
            "cpu family\t: 6\n",
            "model\t\t: 63\n",
            "model name\t: Intel(R) Xeon(R) CPU @ 2.30GHz\n",
            "stepping\t: 0\n",
            "microcode\t: 0x1\n",
            "cpu MHz\t\t: 2299.998\n",
            "cache size\t: 46080 KB\n",
            "physical id\t: 0\n",
            "siblings\t: 2\n",
            "core id\t\t: 0\n",
            "cpu cores\t: 1\n",
            "apicid\t\t: 1\n",
            "initial apicid\t: 1\n",
            "fpu\t\t: yes\n",
            "fpu_exception\t: yes\n",
            "cpuid level\t: 13\n",
            "wp\t\t: yes\n",
            "flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm invpcid_single ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 avx2 smep bmi2 erms invpcid xsaveopt arat md_clear arch_capabilities\n",
            "bugs\t\t: cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs\n",
            "bogomips\t: 4599.99\n",
            "clflush size\t: 64\n",
            "cache_alignment\t: 64\n",
            "address sizes\t: 46 bits physical, 48 bits virtual\n",
            "power management:\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "liQZb4cDmZgy",
        "colab_type": "text"
      },
      "source": [
        "# 2 > 텐서플로우 2.0으로 업데이트하기\n",
        "텐서플로우(tensorflow)와 Keras의 설치 버전을 확인합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jJ_HxbGf5hcO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "84075539-9f67-41be-c42b-dba68b9e5821"
      },
      "source": [
        "import keras\n",
        "import tensorflow as tf\n",
        "\n",
        "print(tf.__version__)\n",
        "print(keras.__version__)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2.2.0\n",
            "2.3.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "arsH-DhLcihq",
        "colab_type": "text"
      },
      "source": [
        "# 3 > GPU 할당 체크하기\n",
        "\"Found GPU at: / device: GPU: 0\"이 표시되면, GPU가 이미 사용중이라는 의미입니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uQgEhuoTcg0N",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1d8c94a5-8222-4124-a57d-cd718ad0e7c3"
      },
      "source": [
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ba2oPDIrsDFg",
        "colab_type": "text"
      },
      "source": [
        "# 4 > Donkeycar 프로그램 설치\n",
        "\n",
        "* Donkeycar의 영상데이타 기반의 학습프로그램을 활용하기 위해서 Donkeycar의 프로그램들을 Google Colaboratory에 설치해야 합니다.\n",
        "\n",
        "* Git에 저장되어 있는 Donkeycar 프로그램 저장소에서 관련 소스코드를 가져와서 Google Colaboratory에 폴더를 생성하고 해당 소스코드를 복사하여 설치합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oOxd9PFUyNxI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "d39de1a6-85f1-45d0-8d32-f2b4d6c23789"
      },
      "source": [
        "!git clone https://github.com/autorope/donkeycar.git donkey"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'donkey'...\n",
            "remote: Enumerating objects: 61, done.\u001b[K\n",
            "remote: Counting objects: 100% (61/61), done.\u001b[K\n",
            "remote: Compressing objects: 100% (52/52), done.\u001b[K\n",
            "remote: Total 13207 (delta 17), reused 33 (delta 7), pack-reused 13146\u001b[K\n",
            "Receiving objects: 100% (13207/13207), 77.64 MiB | 33.70 MiB/s, done.\n",
            "Resolving deltas: 100% (8329/8329), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4E8pOE73l3Fn",
        "colab_type": "text"
      },
      "source": [
        "### (Q) 저장된 Donkeycar 소스코드는 어디에 ?\n",
        "\n",
        "Git에서 가져온 코드들은 Google Colaboratory의 탐색창의 상단의 파일 메뉴를 클릭하면 설치된 소스코드의 디렉토리를 아래와 같이 확인이 가능합니다.\n",
        "\n",
        "* Google Colaboratory의 파일은 /content 아래에 위치합니다.\n",
        "\n",
        "![DonkeyCar Git Source Codes Folder](https://api.monosnap.com/file/download?id=Apc4BB8AwlJ1tryBBykAzdnxvAwTw1)\n",
        "\n",
        "* 사용자가 /content 디렉토리 아래에 mydata라는 새로운 디렉토리(폴더)를 생성했다면, 실제 Google Colaboratory에서는 /content/mydata 라는 폴더가 생성됩니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9TkkcF-gsAnx",
        "colab_type": "text"
      },
      "source": [
        "## 4.1 DonkeyCar 프로그램 설치하기\n",
        "\n",
        "DonkeyCar 프로그램 소스코드가 저장된 donkey폴더 내의 setup.py 파일을 사용해서 설치를 진행합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jz_PZgrByPDh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "outputId": "50548315-319f-4049-bb52-cf461c42d150"
      },
      "source": [
        "!pip3 install -e donkey"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Obtaining file:///content/donkey\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from donkeycar==3.1.3) (1.18.5)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (from donkeycar==3.1.3) (7.0.0)\n",
            "Requirement already satisfied: docopt in /usr/local/lib/python3.6/dist-packages (from donkeycar==3.1.3) (0.6.2)\n",
            "Requirement already satisfied: tornado in /usr/local/lib/python3.6/dist-packages (from donkeycar==3.1.3) (5.1.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from donkeycar==3.1.3) (2.23.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from donkeycar==3.1.3) (2.10.0)\n",
            "Requirement already satisfied: moviepy in /usr/local/lib/python3.6/dist-packages (from donkeycar==3.1.3) (0.2.3.5)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from donkeycar==3.1.3) (1.0.5)\n",
            "Requirement already satisfied: PrettyTable in /usr/local/lib/python3.6/dist-packages (from donkeycar==3.1.3) (0.7.2)\n",
            "Collecting paho-mqtt\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/59/11/1dd5c70f0f27a88a3a05772cd95f6087ac479fac66d9c7752ee5e16ddbbc/paho-mqtt-1.5.0.tar.gz (99kB)\n",
            "\u001b[K     |████████████████████████████████| 102kB 2.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->donkeycar==3.1.3) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->donkeycar==3.1.3) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->donkeycar==3.1.3) (2020.6.20)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->donkeycar==3.1.3) (2.10)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from h5py->donkeycar==3.1.3) (1.15.0)\n",
            "Requirement already satisfied: tqdm<5.0,>=4.11.2 in /usr/local/lib/python3.6/dist-packages (from moviepy->donkeycar==3.1.3) (4.41.1)\n",
            "Requirement already satisfied: decorator<5.0,>=4.0.2 in /usr/local/lib/python3.6/dist-packages (from moviepy->donkeycar==3.1.3) (4.4.2)\n",
            "Requirement already satisfied: imageio<3.0,>=2.1.2 in /usr/local/lib/python3.6/dist-packages (from moviepy->donkeycar==3.1.3) (2.4.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->donkeycar==3.1.3) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas->donkeycar==3.1.3) (2.8.1)\n",
            "Building wheels for collected packages: paho-mqtt\n",
            "  Building wheel for paho-mqtt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for paho-mqtt: filename=paho_mqtt-1.5.0-cp36-none-any.whl size=61416 sha256=c37c31a0116c6b15f9182c737e6925f85ab2516e01c324688c4d3d798aeb7cfc\n",
            "  Stored in directory: /root/.cache/pip/wheels/02/94/6c/8474137cb7a5a3e001d70a22c8ff919caee69435376bccce79\n",
            "Successfully built paho-mqtt\n",
            "Installing collected packages: paho-mqtt, donkeycar\n",
            "  Running setup.py develop for donkeycar\n",
            "Successfully installed donkeycar paho-mqtt-1.5.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "syCctLq2r4Wk",
        "colab_type": "text"
      },
      "source": [
        "## 4.2 DonkeyCar 프로젝트 생성하기\n",
        "\n",
        "DonkeyCar에 대한 나만의 프로젝트를 새로이 생성합니다. 프로젝트를 생성하기 위해서는 프로젝트 이름이 필요합니다. 여기서는 mycar라는 프로젝트명을 사용합니다. Donkeycar의 프로젝트 생성 형식은 다음과 같습니다.\n",
        "\n",
        "$ donkey createcat --path /content/mycar [enter]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1xjJBSITyXy2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "6bd33a26-e44c-40bf-ec30-a27de9976216"
      },
      "source": [
        "!donkey createcar --path /content/mycar"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "using donkey v3.1.3 ...\n",
            "Creating car folder: /content/mycar\n",
            "making dir  /content/mycar\n",
            "Creating data & model folders.\n",
            "making dir  /content/mycar/models\n",
            "making dir  /content/mycar/data\n",
            "making dir  /content/mycar/logs\n",
            "Copying car application template: complete\n",
            "Copying car config defaults. Adjust these before starting your car.\n",
            "Copying train script. Adjust these before starting your car.\n",
            "Copying calibrate script. Adjust these before starting your car.\n",
            "Copying my car config overrides\n",
            "Donkey setup complete.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RkEtUoKIq2Ua",
        "colab_type": "text"
      },
      "source": [
        "### (Q) 생성된 mycar 프로젝트는 어디에 ?\n",
        "\n",
        "탐색창의 파일을 클릭하면, 다음과 같이 /content 디렉토리 아래에 mycar폴더가 새롭게 생성되었다는 것을 확인할 수 있습니다. mycar폴더에는 3개의 폴더와 4개의 파이썬 파일이 생성됩니다.\n",
        "\n",
        "![Donkeycar User-Defined Project Folder](https://api.monosnap.com/file/download?id=yMcfRjpwpEpeZIkCqiq2nfX7ihdFjX)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dnUy1Z1zro77",
        "colab_type": "text"
      },
      "source": [
        "## 4.3 라즈베리파이의 주행데이타를 Google Colaboratory로 이동 준비(PC/노트북)\n",
        "\n",
        "* 라즈베리파이에 저장된 주행 영상데이타는 프로젝트 파일 폴더(예를 들어 mycar라고 가정) 아래에 data 폴더 아래에 tub_라는 이름을 시작하는 폴더에 순차번호를 붙여서 저장되어 있습니다. 예를들어, 폴더명이 tub_1_19-11-09라면, 11월 09일에 주행한 첫번째 주행영상이라는 의미로 해석이 가능합니다(~/mycar/data/tub_1_19-11-09).\n",
        "\n",
        "* 주행데이타는 개별(1회분의 주행영상)은 물론이고 여러개의 풀더(여러번의 주행영상들)을 모두 학습에 활용할 수 있기때문에 우선 PC로 모두 이동하여 저장하는 방법이 유용합니다.\n",
        "\n",
        "* 본 워크샵에서는 Paragon S/W의 extFS for Windows 소프트웨어를 사용해서 라즈베리파이의 SD카드로부터 프로젝트 폴더내 data폴더내의 tub_폴더 데이타를 PC/노트북으로 바로 복사할 수 있습니다. \n",
        "\n",
        "* 라즈베리파이 SD카드로부터 폴더 단위의 복사를 완료했다면, tub_ 폴더들을 Google Laboratory로 업로드하기 위해서 zip으로 묶고, 압축된 파일을 Google Laboratory로 업로드합니다.\n",
        "\n",
        "![Alt text](https://monosnap.com/image/cLWMOMwqgzhLhg2io0DgSBaov7NWKb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ixjmMBKvzrV4",
        "colab_type": "text"
      },
      "source": [
        "## 4.4 Data.zip을 노트북/PC에서 Google Colaboratory로 업로드하기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jvKfQNaOxYQj",
        "colab_type": "text"
      },
      "source": [
        "#####  PC/노트북에서 Google Colaboratory로 압축된 데이타 파일을 업로드하기 위한 절차와 과정은 다음과 같습니다. 해당 과정을 수행하는 코드는 설명 다음 섹션에 있습니다.\n",
        "\n",
        "1. PC/노트북에서 압축된 data.zip파일은 Google Colaboratory에서 지원되는 files.upload() 함수호출을 통해서 업로드합니다. files.upload() 함수는 아래의 그림과 같이 파일을 업로드할 \"파일선택\" 다이얼로그박스를 표시합니다.\n",
        "\n",
        "![Alt text](https://monosnap.com/image/u9s9HnEVpI80aXwS39VncSub4UB3ZM)\n",
        "\n",
        "2. data.zip의 압축된 파일을 업로드하면 진행사항이 표시됩니다. 총 파일의 크기와 진행율을 확인할 수 있습니다.\n",
        "\n",
        "![Alt text](https://monosnap.com/image/HG8xbWd2lfI78AUTfE9v2DypRT7Wne)\n",
        "\n",
        "\n",
        "3. 파일이 업로드되면서 mycar/data 폴더에 data.zip 파일이 새로이 생성되었음을 확인할 수 있습니다.\n",
        "\n",
        "![Alt text](https://monosnap.com/image/zSheABO4HClAKEchK6JSVHydCcX920)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kz4k56hs0TAD",
        "colab_type": "text"
      },
      "source": [
        "#### PC/노트북에서 압축된 주행데이타 파일을 업로드 하기 위한 수행코드는 아래와 같습니다.\n",
        "\n",
        "업로드할 파일은 data.zip 파일명을 가지며, 해당 파일이 업로드되면 아래의 수행코드에 따라 data.zip파일이 mycar/data 폴더에 위치하게 되며, 자동적으로 압축이 해제되어 설치됩니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nqB_I9dsxBoA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "from google.colab import files\n",
        "\n",
        "if(os.path.exists(\"/content/data.zip\")):\n",
        "   os.remove(\"/content/data.zip\")\n",
        "if(os.path.exists(\"/content/mycar/data.zip\")):\n",
        "   os.remove(\"/content/mycar/data.zip\")"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ws3tajS7iaex",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import shutil\n",
        "\n",
        "WORK_FOLDER = \"/content/mycar/data\"\n",
        "if(os.path.exists(WORK_FOLDER) == True):  \n",
        "    shutil.rmtree('/content/mycar/data')\n",
        "os.makedirs(WORK_FOLDER)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wkvP7rkCkR8W",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "0b46b046-274c-4d1e-f515-0ea9ebf27dd7"
      },
      "source": [
        "%pwd"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Kb9gG4WkIIg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c713d099-88d6-4037-a914-cda9c5d5177e"
      },
      "source": [
        "%cd \"/content/mycar\""
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/mycar\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ncx9VYhKjCCJ",
        "colab_type": "code",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "Ly8gQ29weXJpZ2h0IDIwMTcgR29vZ2xlIExMQwovLwovLyBMaWNlbnNlZCB1bmRlciB0aGUgQXBhY2hlIExpY2Vuc2UsIFZlcnNpb24gMi4wICh0aGUgIkxpY2Vuc2UiKTsKLy8geW91IG1heSBub3QgdXNlIHRoaXMgZmlsZSBleGNlcHQgaW4gY29tcGxpYW5jZSB3aXRoIHRoZSBMaWNlbnNlLgovLyBZb3UgbWF5IG9idGFpbiBhIGNvcHkgb2YgdGhlIExpY2Vuc2UgYXQKLy8KLy8gICAgICBodHRwOi8vd3d3LmFwYWNoZS5vcmcvbGljZW5zZXMvTElDRU5TRS0yLjAKLy8KLy8gVW5sZXNzIHJlcXVpcmVkIGJ5IGFwcGxpY2FibGUgbGF3IG9yIGFncmVlZCB0byBpbiB3cml0aW5nLCBzb2Z0d2FyZQovLyBkaXN0cmlidXRlZCB1bmRlciB0aGUgTGljZW5zZSBpcyBkaXN0cmlidXRlZCBvbiBhbiAiQVMgSVMiIEJBU0lTLAovLyBXSVRIT1VUIFdBUlJBTlRJRVMgT1IgQ09ORElUSU9OUyBPRiBBTlkgS0lORCwgZWl0aGVyIGV4cHJlc3Mgb3IgaW1wbGllZC4KLy8gU2VlIHRoZSBMaWNlbnNlIGZvciB0aGUgc3BlY2lmaWMgbGFuZ3VhZ2UgZ292ZXJuaW5nIHBlcm1pc3Npb25zIGFuZAovLyBsaW1pdGF0aW9ucyB1bmRlciB0aGUgTGljZW5zZS4KCi8qKgogKiBAZmlsZW92ZXJ2aWV3IEhlbHBlcnMgZm9yIGdvb2dsZS5jb2xhYiBQeXRob24gbW9kdWxlLgogKi8KKGZ1bmN0aW9uKHNjb3BlKSB7CmZ1bmN0aW9uIHNwYW4odGV4dCwgc3R5bGVBdHRyaWJ1dGVzID0ge30pIHsKICBjb25zdCBlbGVtZW50ID0gZG9jdW1lbnQuY3JlYXRlRWxlbWVudCgnc3BhbicpOwogIGVsZW1lbnQudGV4dENvbnRlbnQgPSB0ZXh0OwogIGZvciAoY29uc3Qga2V5IG9mIE9iamVjdC5rZXlzKHN0eWxlQXR0cmlidXRlcykpIHsKICAgIGVsZW1lbnQuc3R5bGVba2V5XSA9IHN0eWxlQXR0cmlidXRlc1trZXldOwogIH0KICByZXR1cm4gZWxlbWVudDsKfQoKLy8gTWF4IG51bWJlciBvZiBieXRlcyB3aGljaCB3aWxsIGJlIHVwbG9hZGVkIGF0IGEgdGltZS4KY29uc3QgTUFYX1BBWUxPQURfU0laRSA9IDEwMCAqIDEwMjQ7CgpmdW5jdGlvbiBfdXBsb2FkRmlsZXMoaW5wdXRJZCwgb3V0cHV0SWQpIHsKICBjb25zdCBzdGVwcyA9IHVwbG9hZEZpbGVzU3RlcChpbnB1dElkLCBvdXRwdXRJZCk7CiAgY29uc3Qgb3V0cHV0RWxlbWVudCA9IGRvY3VtZW50LmdldEVsZW1lbnRCeUlkKG91dHB1dElkKTsKICAvLyBDYWNoZSBzdGVwcyBvbiB0aGUgb3V0cHV0RWxlbWVudCB0byBtYWtlIGl0IGF2YWlsYWJsZSBmb3IgdGhlIG5leHQgY2FsbAogIC8vIHRvIHVwbG9hZEZpbGVzQ29udGludWUgZnJvbSBQeXRob24uCiAgb3V0cHV0RWxlbWVudC5zdGVwcyA9IHN0ZXBzOwoKICByZXR1cm4gX3VwbG9hZEZpbGVzQ29udGludWUob3V0cHV0SWQpOwp9CgovLyBUaGlzIGlzIHJvdWdobHkgYW4gYXN5bmMgZ2VuZXJhdG9yIChub3Qgc3VwcG9ydGVkIGluIHRoZSBicm93c2VyIHlldCksCi8vIHdoZXJlIHRoZXJlIGFyZSBtdWx0aXBsZSBhc3luY2hyb25vdXMgc3RlcHMgYW5kIHRoZSBQeXRob24gc2lkZSBpcyBnb2luZwovLyB0byBwb2xsIGZvciBjb21wbGV0aW9uIG9mIGVhY2ggc3RlcC4KLy8gVGhpcyB1c2VzIGEgUHJvbWlzZSB0byBibG9jayB0aGUgcHl0aG9uIHNpZGUgb24gY29tcGxldGlvbiBvZiBlYWNoIHN0ZXAsCi8vIHRoZW4gcGFzc2VzIHRoZSByZXN1bHQgb2YgdGhlIHByZXZpb3VzIHN0ZXAgYXMgdGhlIGlucHV0IHRvIHRoZSBuZXh0IHN0ZXAuCmZ1bmN0aW9uIF91cGxvYWRGaWxlc0NvbnRpbnVlKG91dHB1dElkKSB7CiAgY29uc3Qgb3V0cHV0RWxlbWVudCA9IGRvY3VtZW50LmdldEVsZW1lbnRCeUlkKG91dHB1dElkKTsKICBjb25zdCBzdGVwcyA9IG91dHB1dEVsZW1lbnQuc3RlcHM7CgogIGNvbnN0IG5leHQgPSBzdGVwcy5uZXh0KG91dHB1dEVsZW1lbnQubGFzdFByb21pc2VWYWx1ZSk7CiAgcmV0dXJuIFByb21pc2UucmVzb2x2ZShuZXh0LnZhbHVlLnByb21pc2UpLnRoZW4oKHZhbHVlKSA9PiB7CiAgICAvLyBDYWNoZSB0aGUgbGFzdCBwcm9taXNlIHZhbHVlIHRvIG1ha2UgaXQgYXZhaWxhYmxlIHRvIHRoZSBuZXh0CiAgICAvLyBzdGVwIG9mIHRoZSBnZW5lcmF0b3IuCiAgICBvdXRwdXRFbGVtZW50Lmxhc3RQcm9taXNlVmFsdWUgPSB2YWx1ZTsKICAgIHJldHVybiBuZXh0LnZhbHVlLnJlc3BvbnNlOwogIH0pOwp9CgovKioKICogR2VuZXJhdG9yIGZ1bmN0aW9uIHdoaWNoIGlzIGNhbGxlZCBiZXR3ZWVuIGVhY2ggYXN5bmMgc3RlcCBvZiB0aGUgdXBsb2FkCiAqIHByb2Nlc3MuCiAqIEBwYXJhbSB7c3RyaW5nfSBpbnB1dElkIEVsZW1lbnQgSUQgb2YgdGhlIGlucHV0IGZpbGUgcGlja2VyIGVsZW1lbnQuCiAqIEBwYXJhbSB7c3RyaW5nfSBvdXRwdXRJZCBFbGVtZW50IElEIG9mIHRoZSBvdXRwdXQgZGlzcGxheS4KICogQHJldHVybiB7IUl0ZXJhYmxlPCFPYmplY3Q+fSBJdGVyYWJsZSBvZiBuZXh0IHN0ZXBzLgogKi8KZnVuY3Rpb24qIHVwbG9hZEZpbGVzU3RlcChpbnB1dElkLCBvdXRwdXRJZCkgewogIGNvbnN0IGlucHV0RWxlbWVudCA9IGRvY3VtZW50LmdldEVsZW1lbnRCeUlkKGlucHV0SWQpOwogIGlucHV0RWxlbWVudC5kaXNhYmxlZCA9IGZhbHNlOwoKICBjb25zdCBvdXRwdXRFbGVtZW50ID0gZG9jdW1lbnQuZ2V0RWxlbWVudEJ5SWQob3V0cHV0SWQpOwogIG91dHB1dEVsZW1lbnQuaW5uZXJIVE1MID0gJyc7CgogIGNvbnN0IHBpY2tlZFByb21pc2UgPSBuZXcgUHJvbWlzZSgocmVzb2x2ZSkgPT4gewogICAgaW5wdXRFbGVtZW50LmFkZEV2ZW50TGlzdGVuZXIoJ2NoYW5nZScsIChlKSA9PiB7CiAgICAgIHJlc29sdmUoZS50YXJnZXQuZmlsZXMpOwogICAgfSk7CiAgfSk7CgogIGNvbnN0IGNhbmNlbCA9IGRvY3VtZW50LmNyZWF0ZUVsZW1lbnQoJ2J1dHRvbicpOwogIGlucHV0RWxlbWVudC5wYXJlbnRFbGVtZW50LmFwcGVuZENoaWxkKGNhbmNlbCk7CiAgY2FuY2VsLnRleHRDb250ZW50ID0gJ0NhbmNlbCB1cGxvYWQnOwogIGNvbnN0IGNhbmNlbFByb21pc2UgPSBuZXcgUHJvbWlzZSgocmVzb2x2ZSkgPT4gewogICAgY2FuY2VsLm9uY2xpY2sgPSAoKSA9PiB7CiAgICAgIHJlc29sdmUobnVsbCk7CiAgICB9OwogIH0pOwoKICAvLyBXYWl0IGZvciB0aGUgdXNlciB0byBwaWNrIHRoZSBmaWxlcy4KICBjb25zdCBmaWxlcyA9IHlpZWxkIHsKICAgIHByb21pc2U6IFByb21pc2UucmFjZShbcGlja2VkUHJvbWlzZSwgY2FuY2VsUHJvbWlzZV0pLAogICAgcmVzcG9uc2U6IHsKICAgICAgYWN0aW9uOiAnc3RhcnRpbmcnLAogICAgfQogIH07CgogIGNhbmNlbC5yZW1vdmUoKTsKCiAgLy8gRGlzYWJsZSB0aGUgaW5wdXQgZWxlbWVudCBzaW5jZSBmdXJ0aGVyIHBpY2tzIGFyZSBub3QgYWxsb3dlZC4KICBpbnB1dEVsZW1lbnQuZGlzYWJsZWQgPSB0cnVlOwoKICBpZiAoIWZpbGVzKSB7CiAgICByZXR1cm4gewogICAgICByZXNwb25zZTogewogICAgICAgIGFjdGlvbjogJ2NvbXBsZXRlJywKICAgICAgfQogICAgfTsKICB9CgogIGZvciAoY29uc3QgZmlsZSBvZiBmaWxlcykgewogICAgY29uc3QgbGkgPSBkb2N1bWVudC5jcmVhdGVFbGVtZW50KCdsaScpOwogICAgbGkuYXBwZW5kKHNwYW4oZmlsZS5uYW1lLCB7Zm9udFdlaWdodDogJ2JvbGQnfSkpOwogICAgbGkuYXBwZW5kKHNwYW4oCiAgICAgICAgYCgke2ZpbGUudHlwZSB8fCAnbi9hJ30pIC0gJHtmaWxlLnNpemV9IGJ5dGVzLCBgICsKICAgICAgICBgbGFzdCBtb2RpZmllZDogJHsKICAgICAgICAgICAgZmlsZS5sYXN0TW9kaWZpZWREYXRlID8gZmlsZS5sYXN0TW9kaWZpZWREYXRlLnRvTG9jYWxlRGF0ZVN0cmluZygpIDoKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgJ24vYSd9IC0gYCkpOwogICAgY29uc3QgcGVyY2VudCA9IHNwYW4oJzAlIGRvbmUnKTsKICAgIGxpLmFwcGVuZENoaWxkKHBlcmNlbnQpOwoKICAgIG91dHB1dEVsZW1lbnQuYXBwZW5kQ2hpbGQobGkpOwoKICAgIGNvbnN0IGZpbGVEYXRhUHJvbWlzZSA9IG5ldyBQcm9taXNlKChyZXNvbHZlKSA9PiB7CiAgICAgIGNvbnN0IHJlYWRlciA9IG5ldyBGaWxlUmVhZGVyKCk7CiAgICAgIHJlYWRlci5vbmxvYWQgPSAoZSkgPT4gewogICAgICAgIHJlc29sdmUoZS50YXJnZXQucmVzdWx0KTsKICAgICAgfTsKICAgICAgcmVhZGVyLnJlYWRBc0FycmF5QnVmZmVyKGZpbGUpOwogICAgfSk7CiAgICAvLyBXYWl0IGZvciB0aGUgZGF0YSB0byBiZSByZWFkeS4KICAgIGxldCBmaWxlRGF0YSA9IHlpZWxkIHsKICAgICAgcHJvbWlzZTogZmlsZURhdGFQcm9taXNlLAogICAgICByZXNwb25zZTogewogICAgICAgIGFjdGlvbjogJ2NvbnRpbnVlJywKICAgICAgfQogICAgfTsKCiAgICAvLyBVc2UgYSBjaHVua2VkIHNlbmRpbmcgdG8gYXZvaWQgbWVzc2FnZSBzaXplIGxpbWl0cy4gU2VlIGIvNjIxMTU2NjAuCiAgICBsZXQgcG9zaXRpb24gPSAwOwogICAgd2hpbGUgKHBvc2l0aW9uIDwgZmlsZURhdGEuYnl0ZUxlbmd0aCkgewogICAgICBjb25zdCBsZW5ndGggPSBNYXRoLm1pbihmaWxlRGF0YS5ieXRlTGVuZ3RoIC0gcG9zaXRpb24sIE1BWF9QQVlMT0FEX1NJWkUpOwogICAgICBjb25zdCBjaHVuayA9IG5ldyBVaW50OEFycmF5KGZpbGVEYXRhLCBwb3NpdGlvbiwgbGVuZ3RoKTsKICAgICAgcG9zaXRpb24gKz0gbGVuZ3RoOwoKICAgICAgY29uc3QgYmFzZTY0ID0gYnRvYShTdHJpbmcuZnJvbUNoYXJDb2RlLmFwcGx5KG51bGwsIGNodW5rKSk7CiAgICAgIHlpZWxkIHsKICAgICAgICByZXNwb25zZTogewogICAgICAgICAgYWN0aW9uOiAnYXBwZW5kJywKICAgICAgICAgIGZpbGU6IGZpbGUubmFtZSwKICAgICAgICAgIGRhdGE6IGJhc2U2NCwKICAgICAgICB9LAogICAgICB9OwogICAgICBwZXJjZW50LnRleHRDb250ZW50ID0KICAgICAgICAgIGAke01hdGgucm91bmQoKHBvc2l0aW9uIC8gZmlsZURhdGEuYnl0ZUxlbmd0aCkgKiAxMDApfSUgZG9uZWA7CiAgICB9CiAgfQoKICAvLyBBbGwgZG9uZS4KICB5aWVsZCB7CiAgICByZXNwb25zZTogewogICAgICBhY3Rpb246ICdjb21wbGV0ZScsCiAgICB9CiAgfTsKfQoKc2NvcGUuZ29vZ2xlID0gc2NvcGUuZ29vZ2xlIHx8IHt9OwpzY29wZS5nb29nbGUuY29sYWIgPSBzY29wZS5nb29nbGUuY29sYWIgfHwge307CnNjb3BlLmdvb2dsZS5jb2xhYi5fZmlsZXMgPSB7CiAgX3VwbG9hZEZpbGVzLAogIF91cGxvYWRGaWxlc0NvbnRpbnVlLAp9Owp9KShzZWxmKTsK",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "outputId": "4233e070-99ad-4875-97a7-c5ccec3d8e10"
      },
      "source": [
        "uploaded = files.upload()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-4f05b1ed-b0a7-47d3-ab95-41da76f967a8\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-4f05b1ed-b0a7-47d3-ab95-41da76f967a8\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving data.zip to data.zip\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-qGknSMfi8Bp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f2628db5-cc6e-4323-a94d-0a121561922c"
      },
      "source": [
        "!unzip -o data.zip"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  data.zip\n",
            "  inflating: data/.DS_Store          \n",
            "   creating: __MACOSX/\n",
            "   creating: __MACOSX/data/\n",
            "  inflating: __MACOSX/data/._.DS_Store  \n",
            "   creating: data/tub_3_19-11-09/\n",
            "  inflating: data/tub_3_19-11-09/25_cam-image_array_.jpg  \n",
            "  inflating: data/tub_3_19-11-09/18_cam-image_array_.jpg  \n",
            "  inflating: data/tub_3_19-11-09/record_6.json  \n",
            "  inflating: data/tub_3_19-11-09/record_10.json  \n",
            "  inflating: data/tub_3_19-11-09/20_cam-image_array_.jpg  \n",
            "  inflating: data/tub_3_19-11-09/record_26.json  \n",
            "  inflating: data/tub_3_19-11-09/17_cam-image_array_.jpg  \n",
            "  inflating: data/tub_3_19-11-09/12_cam-image_array_.jpg  \n",
            "  inflating: data/tub_3_19-11-09/8_cam-image_array_.jpg  \n",
            "  inflating: data/tub_3_19-11-09/record_27.json  \n",
            "  inflating: data/tub_3_19-11-09/2_cam-image_array_.jpg  \n",
            "   creating: __MACOSX/data/tub_3_19-11-09/\n",
            "  inflating: __MACOSX/data/tub_3_19-11-09/._2_cam-image_array_.jpg  \n",
            "  inflating: data/tub_3_19-11-09/record_11.json  \n",
            "  inflating: data/tub_3_19-11-09/record_7.json  \n",
            "  inflating: data/tub_3_19-11-09/7_cam-image_array_.jpg  \n",
            "  inflating: data/tub_3_19-11-09/record_20.json  \n",
            "  inflating: data/tub_3_19-11-09/16_cam-image_array_.jpg  \n",
            "  inflating: data/tub_3_19-11-09/13_cam-image_array_.jpg  \n",
            "  inflating: data/tub_3_19-11-09/24_cam-image_array_.jpg  \n",
            "  inflating: data/tub_3_19-11-09/21_cam-image_array_.jpg  \n",
            "  inflating: data/tub_3_19-11-09/record_16.json  \n",
            "  inflating: data/tub_3_19-11-09/19_cam-image_array_.jpg  \n",
            "  inflating: data/tub_3_19-11-09/record_17.json  \n",
            "  inflating: data/tub_3_19-11-09/record_1.json  \n",
            "  inflating: data/tub_3_19-11-09/3_cam-image_array_.jpg  \n",
            "  inflating: data/tub_3_19-11-09/6_cam-image_array_.jpg  \n",
            "  inflating: data/tub_3_19-11-09/9_cam-image_array_.jpg  \n",
            "  inflating: data/tub_3_19-11-09/record_21.json  \n",
            "  inflating: data/tub_3_19-11-09/record_18.json  \n",
            "  inflating: data/tub_3_19-11-09/record_22.json  \n",
            "  inflating: data/tub_3_19-11-09/5_cam-image_array_.jpg  \n",
            "  inflating: data/tub_3_19-11-09/record_14.json  \n",
            "  inflating: data/tub_3_19-11-09/record_2.json  \n",
            "  inflating: data/tub_3_19-11-09/22_cam-image_array_.jpg  \n",
            "  inflating: data/tub_3_19-11-09/27_cam-image_array_.jpg  \n",
            "  inflating: data/tub_3_19-11-09/record_3.json  \n",
            "  inflating: data/tub_3_19-11-09/record_15.json  \n",
            "  inflating: data/tub_3_19-11-09/record_23.json  \n",
            "  inflating: data/tub_3_19-11-09/10_cam-image_array_.jpg  \n",
            "  inflating: data/tub_3_19-11-09/record_19.json  \n",
            "  inflating: data/tub_3_19-11-09/15_cam-image_array_.jpg  \n",
            "  inflating: data/tub_3_19-11-09/4_cam-image_array_.jpg  \n",
            "  inflating: data/tub_3_19-11-09/record_12.json  \n",
            "  inflating: data/tub_3_19-11-09/record_4.json  \n",
            "  inflating: data/tub_3_19-11-09/1_cam-image_array_.jpg  \n",
            "  inflating: data/tub_3_19-11-09/record_8.json  \n",
            "  inflating: data/tub_3_19-11-09/record_24.json  \n",
            "  inflating: data/tub_3_19-11-09/record_25.json  \n",
            "  inflating: data/tub_3_19-11-09/11_cam-image_array_.jpg  \n",
            "  inflating: data/tub_3_19-11-09/record_9.json  \n",
            "  inflating: data/tub_3_19-11-09/14_cam-image_array_.jpg  \n",
            "  inflating: data/tub_3_19-11-09/23_cam-image_array_.jpg  \n",
            "  inflating: data/tub_3_19-11-09/record_5.json  \n",
            "  inflating: data/tub_3_19-11-09/meta.json  \n",
            "  inflating: data/tub_3_19-11-09/record_13.json  \n",
            "  inflating: data/tub_3_19-11-09/26_cam-image_array_.jpg  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9-3U5MnYoZPY",
        "colab_type": "text"
      },
      "source": [
        "## 4.4 PC/노트북에서 업로드된 data.zip파일 삭제하기\n",
        "\n",
        "업로드된 data.zip파일을 삭제하여 tub_ 폴더만이 data폴더 안에 위치하도록 합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bXs57m5Nh91O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!rm /content/mycar/data.zip"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T3Ya8qEUAfOv",
        "colab_type": "text"
      },
      "source": [
        "# 5> Donkeycar 주행영상데이타를 활용한 자율주행모델 학습하기\n",
        "\n",
        "동키카에서 지원되는 학습모듈을 사용해서 주행영상 데이타 기반의 인공지능 학습을 진행합니다. CNN(Convolution Neural Network)기반의 이미지 식별을 통한 모델 학습으로 주행영상과 실제 주행시 함께 획득한 속도와 주행방향에 대한 데이타를 입력으로 하여 주행 모델을 학습하게 됩니다.\n",
        "\n",
        "* tub_ 디렉토리가 적은 경우, 학습이 되지 않습니다. 최소 10개이상의 주행을 하고 학습하세요."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "edH3xO_AVWXu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b37a64ac-5bc0-46ab-85fd-52c28c2a4904"
      },
      "source": [
        "!python /content/mycar/manage.py train --model /content/mycar/models/mypilot.h5"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "using donkey v3.1.3 ...\n",
            "loading config file: /content/mycar/config.py\n",
            "myconfig myconfig.py\n",
            "loading personal config over-rides from myconfig.py\n",
            "\n",
            "config loaded\n",
            "2020-08-01 05:54:18.386187: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "using default model type of linear\n",
            "\"get_model_by_type\" model Type is: linear\n",
            "2020-08-01 05:54:20.577813: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
            "2020-08-01 05:54:20.581054: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-01 05:54:20.581849: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: \n",
            "pciBusID: 0000:00:04.0 name: Tesla K80 computeCapability: 3.7\n",
            "coreClock: 0.8235GHz coreCount: 13 deviceMemorySize: 11.17GiB deviceMemoryBandwidth: 223.96GiB/s\n",
            "2020-08-01 05:54:20.581904: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-08-01 05:54:20.583807: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2020-08-01 05:54:20.585721: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2020-08-01 05:54:20.586169: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2020-08-01 05:54:20.588326: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2020-08-01 05:54:20.589296: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2020-08-01 05:54:20.593357: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-08-01 05:54:20.593500: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-01 05:54:20.594220: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-01 05:54:20.594868: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0\n",
            "2020-08-01 05:54:20.600880: I tensorflow/core/platform/profile_utils/cpu_utils.cc:102] CPU Frequency: 2299995000 Hz\n",
            "2020-08-01 05:54:20.601177: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x12c3100 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2020-08-01 05:54:20.601232: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2020-08-01 05:54:20.646568: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-01 05:54:20.647482: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x12c32c0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2020-08-01 05:54:20.647518: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla K80, Compute Capability 3.7\n",
            "2020-08-01 05:54:20.647742: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-01 05:54:20.648500: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: \n",
            "pciBusID: 0000:00:04.0 name: Tesla K80 computeCapability: 3.7\n",
            "coreClock: 0.8235GHz coreCount: 13 deviceMemorySize: 11.17GiB deviceMemoryBandwidth: 223.96GiB/s\n",
            "2020-08-01 05:54:20.648564: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-08-01 05:54:20.648625: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2020-08-01 05:54:20.648670: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2020-08-01 05:54:20.648724: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2020-08-01 05:54:20.648769: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2020-08-01 05:54:20.648813: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2020-08-01 05:54:20.648856: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-08-01 05:54:20.648981: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-01 05:54:20.649871: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-01 05:54:20.650550: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0\n",
            "2020-08-01 05:54:20.650614: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-08-01 05:54:21.086837: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-08-01 05:54:21.086911: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1108]      0 \n",
            "2020-08-01 05:54:21.086933: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] 0:   N \n",
            "2020-08-01 05:54:21.087180: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-01 05:54:21.087994: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-01 05:54:21.088679: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2020-08-01 05:54:21.088739: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1247] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10520 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "training with model type <class 'donkeycar.parts.keras.KerasLinear'>\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "img_in (InputLayer)             [(None, 120, 160, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 58, 78, 24)   1824        img_in[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 58, 78, 24)   0           conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 27, 37, 32)   19232       dropout[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 27, 37, 32)   0           conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 12, 17, 64)   51264       dropout_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2 (Dropout)             (None, 12, 17, 64)   0           conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 10, 15, 64)   36928       dropout_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_3 (Dropout)             (None, 10, 15, 64)   0           conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 8, 13, 64)    36928       dropout_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_4 (Dropout)             (None, 8, 13, 64)    0           conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "flattened (Flatten)             (None, 6656)         0           dropout_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 100)          665700      flattened[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_5 (Dropout)             (None, 100)          0           dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 50)           5050        dropout_5[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_6 (Dropout)             (None, 50)           0           dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "n_outputs0 (Dense)              (None, 1)            51          dropout_6[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "n_outputs1 (Dense)              (None, 1)            51          dropout_6[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 817,028\n",
            "Trainable params: 817,028\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "found 0 pickles writing json records and images in tub /content/mycar/data/tub_3_19-11-09\n",
            "/content/mycar/data/tub_3_19-11-09\n",
            "collating 27 records ...\n",
            "train: 21, val: 6\n",
            "total records: 27\n",
            "steps_per_epoch 0\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/mycar/manage.py\", line 669, in <module>\n",
            "    multi_train(cfg, dirs, model, transfer, model_type, continuous, aug)\n",
            "  File \"/content/mycar/train.py\", line 902, in multi_train\n",
            "    train_fn(cfg, tub, model, transfer, model_type, continuous, aug)\n",
            "  File \"/content/mycar/train.py\", line 536, in train\n",
            "    go_train(kl, cfg, train_gen, val_gen, gen_records, model_name, steps_per_epoch, val_steps, continuous, verbose, save_best)\n",
            "  File \"/content/mycar/train.py\", line 564, in go_train\n",
            "    raise Exception(\"Too little data to train. Please record more records.\")\n",
            "Exception: Too little data to train. Please record more records.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6BEOJYH601O0",
        "colab_type": "text"
      },
      "source": [
        "# 6> 학습한 모델 PC/노트북에 다운로드 하기\n",
        "\n",
        "* Google Colaboratory의 탐색창에서 파일 섹션으로 이동합니다. \n",
        "\n",
        "* Google Colaboratory에서 학습한 모델을 저장하고 있는 디렉토리(models)를 클릭하고 이동합니다. 사용자의 프로젝트 폴더가 mycar라면, mycar/models 디렉토리에 학습한 인공지능 모델이 저장되어 있습니다.\n",
        "\n",
        "* 학습한 모델은 확장자로 *.h5를 사용합니다. 다운로드할 모델파일을 선택하고, 마우스의 오른쪽 버튼을 누르면 선택한 파일의 '다운로드' 메뉴항목이 표시됩니다. 해당 항목을 선택하면 노트북/PC에 모델을 다운로드 할 수 있습니다.\n",
        "\n",
        "\n",
        "![Alt text](https://monosnap.com/image/XpGITFyzwgkqjNI7c40fsv91KRpTqw)\n",
        "\n",
        "* 학습한 모델을 저장한 폴더에는 저장된 모델명 파일(여기서는 mypolot.h5)의 학습과정동안 계산된 loss(손실)과 정확도(accurracy)에 대한 값을 그래프로 표현한 png파일도 함께 저장되어 있습니다. 결과값에 대한 파일명은 \"모델명_loss_acc_정확도실수값.png\"의 형식으로 표현됩니다.\n",
        "\n",
        "<img src=\"https://monosnap.com/image/Xrnv8MfkNS8opa46LAcNvuHnmHPu9Q\" width=\"480\" height=\"320\" />"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hfERkGy821Xy",
        "colab_type": "text"
      },
      "source": [
        "# 7> 자율주행모드로 동키카 운행하기\n",
        "\n",
        "* PC/노트북에 다운로드한 인공지능 모델을 ExtFS for Windows 소프트웨어를 활용해서 라즈베리파이의 SD카드를 읽어들려 해당 프로젝트 파일의 models 폴더에 저장합니다. \n",
        "\n",
        "* 저장이 완료된 모델을 탑재한 라즈베리파이 SD카드를 동키카에 적재하고 동키카에 전원을 넣어 부팅합니다.\n",
        "\n",
        "* 노트북/PC에서 SSH로 동키카에 접속한 후, 아래의 명령을 입력하여 자율주행 모드로의 실행을 설정합니다.\n",
        "\n",
        "```\n",
        "# 동키카에 탑재된 라즈베리파이에서 수행할 코드\n",
        "\n",
        "$cd mycar [enter]\n",
        "$python manage.py drive --model /mycar/models/mypilot.h5 [enter]\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ]
}